# Big-Data-Spark
Create an ETL using PySpark

# OVERVIEW
Create an ETL using PySpark to process OLTP logs data (1 month) into OLAP (for analysis, data visualization, or loading into a database)

# OBJECTIVES
In this task you will create a ETL by performing these steps:
- Read OLTP data from sources (JSON, database, etc.) using Spark.
- Process and normalize the data into an OLAP format.
- Save the data into a database or perform analysis and visualization.

# PROCESS
### 1. Data Source.
```
    data source((9Gb);
```
![data-source](https://github.com/user-attachments/assets/d6032ebd-3e14-448c-85fd-0f75be084bd5)

```
    pre-view data;
```
![pre-view data](https://github.com/user-attachments/assets/4b5d736d-5eed-4048-90ca-b6edb41e98f9)


### 2. Create a Python ETL script to process daily data.
```
   ETL_Script_1.py
```
![image](https://github.com/user-attachments/assets/beeb7b37-ee70-4839-8581-41bf9c10bb2c)





    
    
